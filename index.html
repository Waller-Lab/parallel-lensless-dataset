<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Parallel Lensless Dataset.">

<!-- Social media meta tags -->
<meta property="og:title" content="Scalable dataset acquisition for data-driven lensless imaging">
<meta property="og:description" 
      content="A parallel dataset acqusition for data-driven lensless imaging.">
<meta property="og:url" content="waller-lab.github.io/parallel-lensless-dataset">

  <meta name="keywords" 
      content="computational imaging, dataset, lensless imaging, imaging systems, machine learning, microscopy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Scalable dataset acquisition for data-driven lensless imaging</title>
 
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R9JYPR69ZN"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-R9JYPR69ZN');
</script>



  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    // gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/butterfly_favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$','$'], ['\\(','\\)']],
                displayMath: [['$$','$$'], ['\\[','\\]']],
                processEscapes: true
            }
        });
    </script>

</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <!-- <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div> -->
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item is-hoverable">
        <!-- <a class="navbar-link">
          More Research
        </a> -->
        <div class="navbar-item">
          <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/hardware.html">
            Hardware
          </a>
          <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/software.html">
            Software
          </a>
          <!-- <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/dataset.html">
            Dataset
          </a> -->
        </div>
      </div> 

    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Scalable dataset acquisition for data-driven lensless imaging</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
                <a href="https://www.linkedin.com/in/clarashung/">Clara S. Hung</a>,
            </span>
            <span class="author-block">
              <a href="https://Lakabuli.github.io/">Leyla A. Kabuli</a>,
            </span>
            <span class="author-block">
                <a href="https://www.linkedin.com/in/vasilisa-ponomarenko/">Vasilisa Ponomarenko</a>,
            </span>
            <span class="author-block">
                <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/waller.html">Laura Waller</a>
            </span>
        </div>

   
          <div class="is-size-6 publication-authors">
            <span class="author-block">Department of Electrical Engineering and Computer Sciences</span>
            <br>
            <span class="author-block">University of California, Berkeley</span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              
                <!-- FLAG - add once available -->
                <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://spie.org/photonics-west/presentation/Scalable-dataset-acquisition-for-data-driven-lensless-imaging/13333-60"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2501.13334"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=2bSnbygpeaI"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Waller-Lab/parallel-lensless-dataset"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/1CqPliG5rZIYH5zA6cXdrA6cvDF7obbvc?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Data-driven developments in lensless imaging, such as machine learning-based reconstruction algorithms, require large datasets. In this work, we introduce a data acquisition pipeline that can capture from multiple lensless imaging systems in parallel, paired with computational ground truth registration. Our dataset acquisition system consists of a hardware system for data acquisition and software framework for hardware control and computational processing. We provide an open-access 25,000 image dataset with two lensless imagers, a reproducible hardware setup, and open-source camera synchronization code. Experimental datasets from our system can enable data-driven developments in lensless imaging, such as machine learning-based reconstruction algorithms and end-to-end system design.
          </p>

          <p>
        </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Dataset -->
<section class="section">
  <div class="container is-max-desktop">
  <div class="columns is-centered">
      <div class="container is-max-desktop">
      <div class="content">
          <h2 class="title is-3 section-title">Dataset</h2>

          <p>We provide an open-source, 25,000 image dataset with two lensless imagers—the DiffuserCam and the Random Multi-focal Lenslet (RML) imager—and paired ground truth images. We used MIRFLICKR-25000 as the ground truth dataset. Our dataset consists of:</p>

          <ul>
            <li>25,000 DiffuserCam images</li>
            <li>25,000 RML images</li>
            <li>25,000 ground truth images</li>
            <li>Experimentally captured point spread functions (PSFs)</li>
          </ul>

          <p>The dataset includes a calibration PSF for each imager at an exposure that produced the best results during our tests. We also include a folder of PSFs for both imagers at varying exposures for further experimentation.</p>

          <p>If you use our dataset in our research, we kindly ask that you <a href="#BibTeX">cite our publication.</a></p>

          <a href="https://drive.google.com/drive/folders/1CqPliG5rZIYH5zA6cXdrA6cvDF7obbvc?usp=sharing"
             class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
                <i class="far fa-images"></i>
            </span>
            <span>Access our dataset</span>
          </a>
      </div>
      </div>
  </div>
  </div>
</section>

<!-- Hardware Setup -->
<section class="section">
    <div class="container is-max-desktop">
    <div class="columns is-centered">
        <div class="container is-max-desktop">
        <div class="content">
            <h2 class="title is-3 section-title">Hardware setup</h2>
            <p>Our hardware system captures measurements from multiple lensless imaging systems and a ground truth lensed camera in parallel. We provide a step-by-step tutorial for building our system on our <a href="hardware.html">Hardware Setup</a> page and encourage other researchers to build off of our setup.</p>
            <div class="columns is-centered">
                <div class="column is-10">
                    <figure class="image">
                        <img src="./static/images/hardware-only-04.png" alt="Hardware setup">
                    </figure>
                </div>
              </div>
        </div>
    </div>
    </div>
</section>

<!-- Software Package -->
<section class="section">
    <div class="container is-max-desktop">
    <div class="columns is-centered">
        <div class="container is-max-desktop">
        <div class="content">
            <h2 class="title is-3 section-title">Software package</h2>
            We developed a software package to automate image display and camera capture. For near real-time feedback during calibration and alignment, we use an image reconstruction script thatreconstructs images using 200 iterations of FISTA. Additionally, we correct for lens distortion in the lensed, ground truth camera and achieve pixel-wise alignment between the lensless and lensed images via a learned homography. All code is available on <a href="https://github.com/Waller-Lab/parallel-lensless-dataset">Github</a>, with a detailed usage and calibration guide on our <a href="software.html">Software</a> page.
            <div class="columns is-centered">
              <div class="column column is-10">
                  <figure class="image">
                      <img src="./static/images/software-03.png" alt="Software pipeline">
                  </figure>
              </div>
            </div>
        </div>
        </div>
    </div>
    </div>
</section>

<!-- COLLABORATE!! -->
<section class="section">
    <div class="container is-max-desktop">
    <div class="columns is-centered">
        <div class="container is-max-desktop">
        <div class="content">
            <h2 class="title is-3 section-title">Collaborate with us!</h2>
            <div class="content has-text-justified">
                <p>
                    We are excited to collaborate with researchers broadly in computational imaging and machine learning. If you are interested in using our dataset, have questions about our work, or would like to collaborate, please reach out to <a href="mailto:clarahung@berkeley.edu">clarahung@berkeley.edu</a>.
        </div>
        </div>
    </div>
    </div>
</section>

<!-- START: Related Work -->
<section class="section">
  <div class="columns is-centered">
    <div class="container is-max-desktop">
      <div class="content">
        <h2 class="title is-3">Related Work</h2>
        <div class="content has-text-justified">
          <h3 class="title is-4">Lensless Imagers</h3>
          <ul>
            <li><a href="https://waller-lab.github.io/DiffuserCam/">DiffuserCam</a></li>
            <li><a href="https://opg.optica.org/abstract.cfm?uri=COSI-2023-CW3B.2">Random Multi-focal Lenslet Imager</a></li>
          </ul>

          <h3 class="title is-4">Other Lensless Datasets</h3>
          We link other lensless datasets that are open-access. We welcome suggestions for additional datasets to include, as well as comparisons between our datasets and others.

          <ul>
            <li>
              <a href="https://waller-lab.github.io/LenslessLearning/index.html">Learned reconstructions for practical mask-based lensless imaging</a>
            </li>

            <li>
              <a href="https://opg.optica.org/ol/abstract.cfm?uri=ol-47-7-1843">Image reconstruction with transformer for mask-based lensless imaging</a>
            </li>

            <li>
              <a href="https://siddiquesalman.github.io/flatnet/">FlatNet: Towards Photorealistic Scene Reconstruction from Lensless Measurements</a>
            </li>

            <li>
              <a href="https://computationalimaging.rice.edu/databases/flatcam-face-dataset/">FlatCam Face Dataset</a>
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- END: Related Work -->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{hung2025scalabledatasetacquisitiondatadriven,
      title={Scalable dataset acquisition for data-driven lensless imaging}, 
      author={Clara S. Hung and Leyla A. Kabuli and Vasilisa Ponomarenko and Laura Waller},
      year={2025},
      eprint={2501.13334},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2501.13334}, 
}</code></pre>
  </div>
</section>


<footer class="footer py-2">
  <div class="content has-text-centered">
    <p class="mb-0">
      Website template from <a href="https://nerfies.github.io/">Nerfies</a>
    </p>
  </div>
</footer>

</body>
</html>