<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Parallel Lensless Dataset.">

<!-- Social media meta tags -->
<meta property="og:title" content="Scalable dataset acquisition for data-driven lensless imaging">
<meta property="og:description" 
      content="A parallel dataset acqusition for data-driven lensless imaging.">
<meta property="og:url" content="waller-lab.github.io/parallel-lensless-dataset">

  <meta name="keywords" 
      content="computational imaging, dataset, lensless imaging, imaging systems, machine learning, microscopy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Parallel Lensless Dataset Acquisition</title>
 

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R9JYPR69ZN"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-R9JYPR69ZN');
</script>



  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    // gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$','$'], ['\\(','\\)']],
                displayMath: [['$$','$$'], ['\\[','\\]']],
                processEscapes: true
            }
        });
    </script>

</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <!-- <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div> -->
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item is-hoverable">
        <!-- <a class="navbar-link">
          More Research
        </a> -->
        <div class="navbar-item">
          <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/hardware.html">
            Hardware
          </a>
          <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/software.html">
            Software
          </a>
          <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/datasets.html">
            Datasets
          </a>
        </div>
      </div> 

    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 section-title">Hardware guide</h1>
          
          <div class="columns is-centered">
            <div class="column is-four-fifths">
                <figure class="image">
                    <img src="./static/images/hardware-only-04.png" alt="Hardware setup">
                </figure>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            Our hardware system consists of a monitor for displaying images from the ground truth dataset, two lensless imagers, and a ground truth lensed camera. Though we use two lensless imagers in our setup, the DiffuserCam and Random Multi-Focal Lenslet (RML) imager, the hardware setup can be easily modified to accommodate other lensless imaging systems. This page will be updated with detailed instructions on building and troubleshooting the hardware system.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>



<!-- EQUIPMENT -->
  <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="container is-max-desktop">
            <div class="content">
              <h2 class="title is-3 section-title">Equipment</h2>
              <p>Below is a list of equipment we used for our hardware setup and the model. Feel free to use different models for your own convinience.</p>

              <ul>
                <li>Portable monitor: INNOCN 13A1F</li>
                <li>Board level sensors: Basler daA1920-160uc</li>
                <li>Lensed camera mount and lens: Evetar S-mount, f=6 mm lens</li>
                <li>50/50 split ratio beamsplitter: ThorLabs BS031</li>
                <li>Diffuser: Luminit 0.5Â°</li>
                <li>Basler USB 3.1 Hub</li>
                <li>ThorLabs KM100C - Kinematic Mount</li>
                <li>Custom 3D printed <a href="https://cad.onshape.com/documents/8b5cffba73557ce58bb90b17/w/baa6ec16d1a4ec1d4b8a031d/e/bc4b23f9163d5ebb2c59158a">2-to-1 mount</a></li>
              </ul>

            </div>
          </div>
        </div>
      </div>
  </section>

  <!-- TUTORIAL -->
  <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="container is-max-desktop">
        <div class="content">
          <h2 class="title is-3 section-title">Building the system</h2>
          <p>We chose to build our system on an optical breadboard so it can be portable for in-the-wild captures. We used a breadboard that was readily available in our lab, which set size constraints of our system. All sensors are connected to power through the Basler USB Hub.</p>

          <h3 class="title is-4 section-title">1. Mount the ground truth camera</h3>
          <p>First, we mounted an f=6 mm lens to our board level sensors using an S-mount. Then, we mounted the camera onto a right-handed kinematic mount. We added double-sided tape to the clamps of the mount to minimize wiggling.</p>
          <div class="columns">
            <div class="column">
              <img src="./static/images/lensed_tape.jpg" alt="Taping the lensed camera">
              <p class="has-text-centered is-size-7">Taping the lensed camera</p>
            </div>
            <div class="column">
              <img src="./static/images/lensed_back.jpg" alt="Back view of mounted lensed camera">
              <p class="has-text-centered is-size-7">Back view of mounted lensed camera</p>
            </div>
          </div>

          <h3 class="title is-4 section-title">2. Build the lensless imagers</h3>
          <p>For both the RML and DiffuserCam, we first mounted the board level sensors onto a 2-to-1 baseplate. Because the Basler board level sensors we used were not compatible with our existing baseplates, we 3D printed a <a href="https://cad.onshape.com/documents/8b5cffba73557ce58bb90b17/w/baa6ec16d1a4ec1d4b8a031d/e/bc4b23f9163d5ebb2c59158a">custom 2-to-1 mount</a> that allowed us to attach our lensless imagers to an off-the-shelf Thorlabs plate. This would allow us to attach the Thorlabs plate to an optical post.</p> 

            <p>To build the DiffuserCam, we taped a piece of diffuser (large enough to cover the sensor) onto the mounted board level by putting double-sided tape on its screws, roughly 4.5mm from the sensor. We also added padding using layers of tape. We created a small aperture using black masking tape by shining a point source at the imaging distance and created an aperture to limit the PSF extent to the center of the sensor. More details can be found <a href="https://waller-lab.github.io/DiffuserCam/">here</a>.</p>

          <div class="columns">
            <div class="column">
              <img src="./static/images/mounted_sensor.jpeg" alt="Board level sensor mounted on a custom 3D printed mount and Thorlabs baseplate">
              <p class="has-text-centered is-size-7">Board level sensor mounted on a custom 3D printed mount and Thorlabs baseplate</p>
            </div>
            <div class="column">
              <img src="./static/images/diffusercam.jpeg" alt="Our mounted DiffuserCam">
              <p class="has-text-centered is-size-7">Our mounted DiffuserCam</p>
            </div>
            <div class="column">
              <img src="./static/images/beamsplitter.jpeg" alt="Aligning the beamsplitter, lensed camera, and DiffuserCam">
              <p class="has-text-centered is-size-7">Aligning the beamsplitter, lensed camera, and DiffuserCam</p>
            </div>
          </div>

          <p>To build the RML, we mounted a custom RML phase mask onto an optical post. Using black masking tape and black cardboard, we built a small enclosure around the mounted board level sensor to block stray light. Having the board level sensor and RML on two separate optical posts makes alignment easier.</p>

          <h3 class="title is-4 section-title">3. Place components on breadboard</h3>
          <p>First, we placed our display screen at the edge of the breadboard. We decided to place our display screen horizontally to maximize the size of the images we could display. We secured the display using clamps on both sides which allowed us to easily remove the display by loosening the clamps. We divided the display in half with a black separator, leaving one side for the RML and the other for the DiffuserCam and lensed camera. We chose to split the DiffuserCam with the beamsplitter due to higher light throughput of the Gaussian diffuser. Then, we placed the beamsplitter ~12cm away from the display screen. We aligned the lensed camera and DiffuserCam to the beamsplitter using a point source (30mm and 25mm from the edge of the beamsplitter to sensor, respectively). </p>

          <p>On the other side, we placed the mounted board level for the RML ~150mm from the display screen. To it, we aligned the RML phase mask 18mm from the sensor. The RML and DiffuserCam are 135mm apart horizontally, parallel to the display.</p>

          <div class="columns">
            <div class="column">
              <img src="./static/images/calibrating_rml.jpeg" alt="Calibrating the RML using a point source">
              <p class="has-text-centered is-size-7">Calibrating the RML using a point source</p>
            </div>
            <div class="column">
              <img src="./static/images/clamps.jpeg" alt="Clamps installed to secure the display">
              <p class="has-text-centered is-size-7">Clamps installed to secure the display</p>
            </div>
            
            <div class="column">
              <img src="./static/images/two_imagers.jpeg" alt="DiffuserCam, lensed camera, and RML on the breadboard">
              <p class="has-text-centered is-size-7">DiffuserCam, lensed camera, and RML on the breadboard</p>
            </div>
          </div>

          <h3 class="title is-4 section-title">4. Aligning and calibrating the imagers</h3>
          <p>After placing components on the breadboard and coarsely aligning them, we optically aligned the imagers (which includes making sure the sensors are on-axis with the display screen) and acquired calibration PSFs.</p>

          <p> For the lensed camera, we displayed a test image and adjusted the focus ring until it was in focus with the surface of the screen. For the RML and DiffuserCam, we placed a point source at the same depth as the display. Then, we adjusted the height of the point source such that the PSF was vertically centered on the sensor. Lastly, we adjusted the tilt of the point source such that it would produce the brightest PSF, which meant the point source is on-axis with the phase mask.</p>

          <h3 class="title is-4 section-title">5. Correct for stray light</h3>
          <p>Before capturing data, we corrected for stray light as much as possible. We built an enclosure around the system using black cardboard and matte black foil to block ambient light. We added dividers between the display and the beamsplitter to prevent the lensed camera and DiffuserCam from capturing light directly from the display instead of through the beamsplitter. We also built small enclosures around the lensless sensors to prevent the sensors from capturing ambient light.</p>

          <div class="columns">
            <div class="column">
              <img src="./static/images/dividers.jpg" alt="Dividers between display and beamsplitter to control for stray light.">
              <p class="has-text-centered is-size-7">Dividers between display and beamsplitter to control for stray light.</p>
            </div>
            <div class="column">
              <img src="./static/images/full.jpeg" alt="Full hardware set up with images being displayed.">
              <p class="has-text-centered is-size-7">Full hardware set up with images being displayed.</p>
            </div>
            <!-- <div class="column">
              <img src="./static/images/calibrating_rml.jpeg" alt="Calibrating the RML using a point source">
              <p class="has-text-centered is-size-7">Calibrating the RML using a point source</p>
            </div> -->
          </div>

        </div>
      </div>
    </div>
  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{pinkard2024informationdrivendesignimagingsystems,
        title={Information-driven design of imaging systems}, 
        author={Henry Pinkard and Leyla Kabuli and Eric Markley and Tiffany Chien and Jiantao Jiao and Laura Waller},
        year={2024},
        eprint={2405.20559},
        archivePrefix={arXiv},
        primaryClass={physics.optics},
        url={https://arxiv.org/abs/2405.20559}, 
      }
</code></pre>
  </div>
</section> -->


<footer class="footer py-2">
  <div class="content has-text-centered">
    <p class="mb-0">
      Website template from <a href="https://nerfies.github.io/">Nerfies</a>
    </p>
  </div>
</footer>

</body>
</html>