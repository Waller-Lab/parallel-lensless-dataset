<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Parallel Lensless Dataset.">

<!-- Social media meta tags -->
<meta property="og:title" content="Information-Driven Design of Imaging Systems">
<meta property="og:description" 
      content="A parallel dataset acqusition for data-driven lensless imaging.">
<meta property="og:url" content="waller-lab.github.io/parallel-lensless-dataset">

  <meta name="keywords" 
      content="computational imaging, dataset, lensless imaging, imaging systems, machine learning, microscopy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Parallel Lensless Dataset Acquisition</title>
 
<!-- Google tag (gtag.js) -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-7DPEDT2PJZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7DPEDT2PJZ');
</script> -->



  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    // gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$','$'], ['\\(','\\)']],
                displayMath: [['$$','$$'], ['\\[','\\]']],
                processEscapes: true
            }
        });
    </script>

</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <!-- <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div> -->
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item is-hoverable">
        <!-- <a class="navbar-link">
          More Research
        </a> -->
        <div class="navbar-item">
          <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/hardware.html">
            Hardware
          </a>
          <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/software.html">
            Software
          </a>
          <a class="navbar-item" href="https://waller-lab.github.io/parallel-lensless-dataset/datasets.html">
            Datasets
          </a>
        </div>
      </div> 

    </div>

  </div>
</nav>

<section class="section">
  <div class="container is-max-desktop">
    
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Datasets</h2>
        <div class="content has-text-justified">
        <p>
          This page provides an overview of how to use our datasets. We provide the following (see the section below for sub-directory organization):
          <!-- BUTTONS -->
        <div class="buttons is-centered">
          <a href="https://drive.google.com/drive/folders/1QxMBwavjwrUELhgV1_pFcdRqsZqzU629"
               class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                  <i class="far fa-images"></i>
              </span>
              <span>25,000 image dataset</span>
            </a>

            <a href="https://drive.google.com/drive/folders/1tY0lgakSKO-ztF5A_ulVPBQDTz4eh7T5?usp=sharing"
               class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                  <i class="far fa-images"></i>
              </span>
              <span>100,000 image dataset</span>
            </a>
        </div>
          <ul>
            <li>Example <a href="https://github.com/Waller-Lab/parallel-lensless-dataset/blob/main/parallel-dataset/tutorials/preprocess.ipynb">iPython Notebook</a> for processing the original measurements for homography warping and for processing the measurements for machine learning training.</li>
            <li>Experimentally captured point spread function (PSF) measurements. <a href="https://drive.google.com/drive/folders/1LMcOIiAGsAAWDenUHhxdIG7DVw_tGrvd?usp=sharing">[LINK]</a></li>

        <!-- DEJARGON HERE -->
            <li>The original, full resolution RML, DiffuserCam, and Ground Truth Lensed measurements. <a href="https://drive.google.com/drive/folders/1SwRUQGZ4nsQVhe1KPJ7MDL5d8CKtx9zu?usp=sharing">[LINK]</a></li>
            <li>Ground truth lensed measurements at 8x downsampling with lens distortion removed and aligned to lensless imagers. <a href="https://drive.google.com/drive/folders/1D8frfCtFoi3REklvPk--Tl55SCADH4PH?usp=sharing">[LINK]</a></li>
            <li>Homographies mapping from Ground Truth to RML and Ground Truth to DiffuserCam at 8x downsampling. <a href="https://drive.google.com/drive/folders/1IRx5_XrReercmUMlgr-F1-PYxSOY-_Mq?usp=sharing">[LINK]</a></li>
          </ul>
        </p>
        </div>
      </div>
    </div>

    <hr>

    <!-- Explain the directory -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">The dataset directory</h2>
        <div class="content has-text-justified">
        <p>
          Our dataset directory is organized as follows:
          <pre><code>
            100k Dataset/
            ├── (1) Full Resolution Measurements/
            │   ├── 0-25k/
            |   │   ├── diffusercam/
            |   │   ├── ground_truth/
            |   │   ├── rml/
            |   │   └── undistorted_ground_truth_images/
            │   ├── 25k-50k/
            │   ├── 50k-75k/
            │   └── 75k-100k/
            ├── (2) PSFs/
            │   ├── mono8_psfs/
            │   ├── mono12_psfs/
            │   └── rgb_psfs/
            ├── (3) Homographies/
            │   ├── Ground Truth to Lensless Imager/
            ├───└── Lensless Imager to Ground Truth/
            └───(4) 8x Downsampled Registered Ground Truth to Imager Space/
          </code></pre>
          Folder (1) contains full resolution measurements of 100,000 images, split into 25,000 folders which each contain a folder for each imager: the DiffuserCam, ground truth lensed camera, and RML. We also include the undistorted version of the lensed images.</p>

          <p>Folder (2) contains PSFs for each imager in Mono8, Mono12, and RGB8 color formats.</p>

          <p>Folder (3) contains <code>.npy</code> files storing homography transformations from the lensed camera to both lensless imagers and from the lensless imagers to the lensed camera at 8x downsampling.</p>

          <p>Folder (4) contains 8x downsampled versions of the undistorted lensed measurements warped to the space of the lensless imagers.</p>

          <p><strong>25,000 Image Dataset:</strong> We also include a separate folder that follows a similar sub-directory structure for those who only want to interface with the 25,000 image dataset, linked above.</p>
        </p>
        </div>
      </div>
    </div>

    <!-- Explain the difference between the two homographies -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Preparing the data for downstream tasks</h2>
        <div class="content has-text-justified">
        <p>With our dataset, we provide two types of homography transforms that can be used to ensure the alignment of lensed ground truth and lensless measurements:
        </p>
        <ul>
          <li>
            Homography from Ground Truth to Lensless Imager: warps the ground truth lensed camera to the spaces of each lensless imager (DiffuserCam and RML). 
          </li>
          <li>
            Homography from Lensless Imager to Ground Truth: warps each lensless imager to the space of the ground truth lensed camera. Useful for fair comparison across all three imagers.
          </li>
        </ul>
        <p>These are for 8x downsampled versions of the dataset. We anticipate providing homographies for 4x and 2x downsampling in the future.</p>
        <p>
          We provide an <a href="https://github.com/Waller-Lab/parallel-lensless-dataset/blob/main/parallel-dataset/tutorials/preprocess.ipynb">iPython Notebook</a> tutorial that walks users step-by-step through how to prepare our dataset to be used in their own projects. Using the 8x downsampled measurements as a starting point, the tutorial includes loading lensed measurements, downsampling lensless measurements, and preparing the data for training and evaluation view.
        </p>
        </div>
      </div>
    </div>

  </div>
</section>




      <!-- <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="container is-max-desktop">
            <div class="content">
              <h2 class="title is-3 section-title">Information Estimation Framework</h2>
            </div>
          </div>
        </div>
      </div>
  </section> -->


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{pinkard2024informationdrivendesignimagingsystems,
        title={Information-driven design of imaging systems}, 
        author={Henry Pinkard and Leyla Kabuli and Eric Markley and Tiffany Chien and Jiantao Jiao and Laura Waller},
        year={2024},
        eprint={2405.20559},
        archivePrefix={arXiv},
        primaryClass={physics.optics},
        url={https://arxiv.org/abs/2405.20559}, 
      }
</code></pre>
  </div>
</section> -->


<footer class="footer py-2">
  <div class="content has-text-centered">
    <p class="mb-0">
      Website template from <a href="https://nerfies.github.io/">Nerfies</a>
    </p>
  </div>
</footer>

</body>
</html>